{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b902c28-4f2c-43c1-b73d-173719cf79b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your choice of 'Risk Term' will define the timeframe with which we will analyze stock returns\n",
      "Select a risk term that matches your current investment goals for collecting returns from stock investments\n",
      "\n",
      "Choose a Risk Term From These Options:\n",
      "1. 1Yrs (1 Year)\n",
      "2. 5Yrs (5 Years)\n",
      "3. 10Yrs (10 Years)\n",
      "4. 15Yrs (15 Years)\n",
      "5. 7Dys (7 Days)\n",
      "6. 21Dys (21 Days)\n",
      "7. 40Dys (40 Days)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your risk term 40Dys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Your choice of 'Risk Threshold' will define how risky and volatile the stocks in the final portfolio will be\n",
      "Select a risk threshold that matches your comfort levels when it comes to risk\n",
      "\n",
      "Choose a Risk Threshold:\n",
      "1. high\n",
      "2. mid\n",
      "3. low\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your risk threshold mid\n"
     ]
    }
   ],
   "source": [
    "#USER INPUT\n",
    "\n",
    "#TRADE TERM\n",
    "print(\"Your choice of 'Risk Term' will define the timeframe with which we will analyze stock returns\")\n",
    "print(\"Select a risk term that matches your current investment goals for collecting returns from stock investments\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Choose a Risk Term From These Options:\")\n",
    "print(\"1. 1Yrs (1 Year)\")\n",
    "print(\"2. 5Yrs (5 Years)\")\n",
    "print(\"3. 10Yrs (10 Years)\")\n",
    "print(\"4. 15Yrs (15 Years)\")\n",
    "print(\"5. 7Dys (7 Days)\")\n",
    "print(\"6. 21Dys (21 Days)\")\n",
    "print(\"7. 40Dys (40 Days)\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "user_trade_term= input(\"Enter your risk term\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "#RISK THRESHOLD\n",
    "print(\"Your choice of 'Risk Threshold' will define how risky and volatile the stocks in the final portfolio will be\")\n",
    "print(\"Select a risk threshold that matches your comfort levels when it comes to risk\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Choose a Risk Threshold:\")\n",
    "print(\"1. high\")\n",
    "print(\"2. mid\")\n",
    "print(\"3. low\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "user_risk= input(\"Enter your risk threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e5ac65b-385c-4888-a976-5cc9b5682cbe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pytz\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "298492c5-ce09-4c28-8960-75bf9c1af0c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Industry_Tag</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-20 04:00:00+00:00</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>4.910000</td>\n",
       "      <td>4.630000</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>7441900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>peloton</td>\n",
       "      <td>PTON</td>\n",
       "      <td>fitness</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-20 04:00:00+00:00</td>\n",
       "      <td>397.049988</td>\n",
       "      <td>397.989990</td>\n",
       "      <td>386.119995</td>\n",
       "      <td>386.299988</td>\n",
       "      <td>3866600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>netflix</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-20 04:00:00+00:00</td>\n",
       "      <td>564.349976</td>\n",
       "      <td>569.219971</td>\n",
       "      <td>562.659973</td>\n",
       "      <td>563.830017</td>\n",
       "      <td>1311500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>costco</td>\n",
       "      <td>COST</td>\n",
       "      <td>retail</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-20 04:00:00+00:00</td>\n",
       "      <td>138.550003</td>\n",
       "      <td>139.369995</td>\n",
       "      <td>135.199997</td>\n",
       "      <td>135.289993</td>\n",
       "      <td>46263700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>amazon</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>e-commerce</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-20 04:00:00+00:00</td>\n",
       "      <td>179.259995</td>\n",
       "      <td>179.699997</td>\n",
       "      <td>175.399994</td>\n",
       "      <td>175.490005</td>\n",
       "      <td>58436200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>apple</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>technology</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279748</th>\n",
       "      <td>2023-08-29 04:00:00+00:00</td>\n",
       "      <td>18.719999</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>18.020000</td>\n",
       "      <td>18.320000</td>\n",
       "      <td>5949600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foot locker</td>\n",
       "      <td>FL</td>\n",
       "      <td>footwear</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279749</th>\n",
       "      <td>2023-08-30 04:00:00+00:00</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>18.650000</td>\n",
       "      <td>17.879999</td>\n",
       "      <td>18.549999</td>\n",
       "      <td>5829500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foot locker</td>\n",
       "      <td>FL</td>\n",
       "      <td>footwear</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279750</th>\n",
       "      <td>2023-08-31 04:00:00+00:00</td>\n",
       "      <td>18.620001</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>18.469999</td>\n",
       "      <td>19.620001</td>\n",
       "      <td>6316100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foot locker</td>\n",
       "      <td>FL</td>\n",
       "      <td>footwear</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279751</th>\n",
       "      <td>2023-09-01 04:00:00+00:00</td>\n",
       "      <td>19.660000</td>\n",
       "      <td>20.139999</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>19.870001</td>\n",
       "      <td>3982400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foot locker</td>\n",
       "      <td>FL</td>\n",
       "      <td>footwear</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279752</th>\n",
       "      <td>2023-09-05 04:00:00+00:00</td>\n",
       "      <td>19.730000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>18.820000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>5862600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foot locker</td>\n",
       "      <td>FL</td>\n",
       "      <td>footwear</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219695 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date        Open        High         Low  \\\n",
       "0      2023-09-20 04:00:00+00:00    4.840000    4.910000    4.630000   \n",
       "1      2023-09-20 04:00:00+00:00  397.049988  397.989990  386.119995   \n",
       "2      2023-09-20 04:00:00+00:00  564.349976  569.219971  562.659973   \n",
       "3      2023-09-20 04:00:00+00:00  138.550003  139.369995  135.199997   \n",
       "4      2023-09-20 04:00:00+00:00  179.259995  179.699997  175.399994   \n",
       "...                          ...         ...         ...         ...   \n",
       "279748 2023-08-29 04:00:00+00:00   18.719999   18.770000   18.020000   \n",
       "279749 2023-08-30 04:00:00+00:00   18.180000   18.650000   17.879999   \n",
       "279750 2023-08-31 04:00:00+00:00   18.620001   19.850000   18.469999   \n",
       "279751 2023-09-01 04:00:00+00:00   19.660000   20.139999   19.400000   \n",
       "279752 2023-09-05 04:00:00+00:00   19.730000   19.930000   18.820000   \n",
       "\n",
       "             Close      Volume  Dividends  Stock Splits   Brand_Name Ticker  \\\n",
       "0         4.670000   7441900.0        0.0           0.0      peloton   PTON   \n",
       "1       386.299988   3866600.0        0.0           0.0      netflix   NFLX   \n",
       "2       563.830017   1311500.0        0.0           0.0       costco   COST   \n",
       "3       135.289993  46263700.0        0.0           0.0       amazon   AMZN   \n",
       "4       175.490005  58436200.0        0.0           0.0        apple   AAPL   \n",
       "...            ...         ...        ...           ...          ...    ...   \n",
       "279748   18.320000   5949600.0        0.0           0.0  foot locker     FL   \n",
       "279749   18.549999   5829500.0        0.0           0.0  foot locker     FL   \n",
       "279750   19.620001   6316100.0        0.0           0.0  foot locker     FL   \n",
       "279751   19.870001   3982400.0        0.0           0.0  foot locker     FL   \n",
       "279752   18.840000   5862600.0        0.0           0.0  foot locker     FL   \n",
       "\n",
       "         Industry_Tag Country  \n",
       "0             fitness     usa  \n",
       "1       entertainment     usa  \n",
       "2              retail     usa  \n",
       "3          e-commerce     usa  \n",
       "4          technology     usa  \n",
       "...               ...     ...  \n",
       "279748       footwear     usa  \n",
       "279749       footwear     usa  \n",
       "279750       footwear     usa  \n",
       "279751       footwear     usa  \n",
       "279752       footwear     usa  \n",
       "\n",
       "[219695 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "World_Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268cd8cd-d21f-425e-945c-b668acef5302",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oluwa\\AppData\\Local\\Temp\\ipykernel_23316\\323580395.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Smaller_Dataframe['Date'] = Smaller_Dataframe['Date'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "#Create Term Splitting Logic\n",
    "while True:\n",
    "    if user_trade_term == '15Yrs':\n",
    "        trade_term = 15\n",
    "        break\n",
    "    elif user_trade_term == '10Yrs':\n",
    "        trade_term = 10\n",
    "        break\n",
    "    elif user_trade_term == '5Yrs':\n",
    "        trade_term = 5\n",
    "        break\n",
    "    elif user_trade_term == '1Yrs':\n",
    "        trade_term = 1\n",
    "        break\n",
    "    elif user_trade_term == '21Dys':\n",
    "        trade_term = 0.0575342\n",
    "        break\n",
    "    elif user_trade_term == '7Dys':\n",
    "        trade_term = 0.0191781\n",
    "        break\n",
    "    elif user_trade_term == '40Dys':\n",
    "        trade_term = 0.109589\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid user_trade_term value\")\n",
    "        user_trade_term= input(\"Enter your trade term\")\n",
    "\n",
    "while True:\n",
    "    if user_risk in ['high', 'mid', 'low']:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid user_risk value\")\n",
    "        user_risk= input(\"Enter your risk threshold\")\n",
    "    \n",
    "# Read in the stocks dataset to clean it\n",
    "World_Stocks = pd.read_csv(Path(r\"C:\\Users\\Oluwa\\GITHUB\\Bootcamp\\ASSIGNMENTS\\Project_Uno\\Resources\\World-Stock-Prices-Dataset.csv\"))\n",
    "\n",
    "#Cut dataset down to US stocks only\n",
    "World_Stocks = World_Stocks[World_Stocks['Country'] == 'usa']\n",
    "\n",
    "#Read in the bond yields dataset for later\n",
    "Bond_yields = pd.read_csv(Path(r\"C:\\Users\\Oluwa\\GITHUB\\Bootcamp\\ASSIGNMENTS\\Project_Uno\\Resources\\bond_yields_all.csv\"))\n",
    "                         \n",
    "# Specify the format of the 'Date' column and save it as a variable\n",
    "date_format = '%Y-%m-%d %H:%M:%S%z'\n",
    "\n",
    "# Use the variable to reformat the column using a universal timezone and handle errors\n",
    "try:\n",
    "    World_Stocks['Date'] = pd.to_datetime(World_Stocks['Date'], format=date_format, utc=True, errors='coerce')\n",
    "#Use the except functionality to print an error if this doesnt work\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while parsing datetime values: {e}\")\n",
    "\n",
    "#Make sure Bond_yields has the same format\n",
    "Bond_yields['Date'] = pd.to_datetime(Bond_yields['date'], format=date_format, utc=True, errors='coerce')\n",
    "\n",
    "# Set 'Date' format to match 'World_Stocks' and fill missing values with 0\n",
    "Bond_yields['Date'] = Bond_yields['Date'].dt.strftime('%Y-%m-%d %H:%M:%S%z')\n",
    "Bond_yields.fillna(0, inplace=True)\n",
    "\n",
    "Yr5_Bond=Bond_yields.drop(columns='date') #cleanup\n",
    "\n",
    "# Convert the 'Date' column to datetime\n",
    "Yr5_Bond['Date'] = pd.to_datetime(Yr5_Bond['Date'], format='%Y-%m-%d %H:%M:%S%z', errors='coerce')\n",
    "Yr5_Bond.fillna(0, inplace=True)\n",
    "\n",
    "# Make sure all stock data calls cut off at the same datetime by making their timezones match\n",
    "cutoff_date = datetime(2023, 9, 20) - timedelta(days=365 * trade_term)\n",
    "\n",
    "# Convert cutoff_date to a string with timezone information\n",
    "cutoff_date_str = cutoff_date.strftime(date_format)\n",
    "\n",
    "# Manually add UTC offset to the string (+00:00 for UTC) | Ensure that all dates in the string match the UTC format\n",
    "cutoff_date_str += '+00:00'\n",
    "\n",
    "# Parse the string back to a datetime64 object with the same timezone\n",
    "try:\n",
    "    cutoff_date = pd.to_datetime(cutoff_date_str, format=date_format, utc=True)\n",
    "#Use the except functionality to print an error if this doesnt work\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while parsing the cutoff_date: {e}\")\n",
    "\n",
    "#Replace the timezone information with the one from the first date of the dataframe. Normalizing all the date data.\n",
    "cutoff_date = cutoff_date.replace(tzinfo=World_Stocks['Date'].iloc[0].tzinfo)\n",
    "\n",
    "# Create a new dataframe variable with only the cells that are after the cut off date\n",
    "Smaller_Dataframe = World_Stocks[World_Stocks['Date'] >= cutoff_date]\n",
    "\n",
    "# Convert the 'Date' column in 'Yr5_Bond' to string format\n",
    "Yr5_Bond['Date'] = Yr5_Bond['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Convert the 'Date' column in Smaller_Dataframe to string format\n",
    "Smaller_Dataframe['Date'] = Smaller_Dataframe['Date'].astype(str)\n",
    "\n",
    "# Extract the first 10 characters from the 'Date' column in 'Smaller_Dataframe'\n",
    "matching_dates = Smaller_Dataframe['Date'].str[:10].unique()\n",
    "\n",
    "# Filter 'Yr5_Bond' based on matching dates\n",
    "Bond_yields_filtered = Yr5_Bond[Yr5_Bond['Date'].str[:10].isin(matching_dates)]\n",
    "\n",
    "# Convert 'Date' column in 'Yr5_Bond' back to the original datetime format\n",
    "Yr5_Bond['Date'] = pd.to_datetime(Yr5_Bond['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# Convert 'Date' column in 'Bond_yields_filtered' back to the original datetime format\n",
    "Bond_yields_filtered['Date'] = pd.to_datetime(Bond_yields_filtered['Date'], format='%Y-%m-%d')\n",
    "\n",
    "#For some reason I couldnt organize the dataframe unless I explicitly copied it. Tried to just make it a variable\n",
    "Calculations_df = Smaller_Dataframe.copy()\n",
    "\n",
    "#Sort the dataframe and clean the data\n",
    "Calculations_df.sort_values(['Ticker', 'Date'], inplace=True)\n",
    "Useless_Columns=['Dividends', 'Stock Splits']\n",
    "Calculations_df.drop(columns=Useless_Columns)\n",
    "Calculations_df.dropna()\n",
    "Compared_Calcs= Calculations_df.groupby(['Date', 'Ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76324490-1724-40b8-8b9d-0224fa82512c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import data for S&P 50 from Yahoo\n",
    "ticker_symbols = '^GSPC'\n",
    "\n",
    "#Set variables for later\n",
    "end_date = datetime(2023, 9, 20)\n",
    "end_date = end_date.replace(tzinfo=pytz.UTC)\n",
    "start_date = end_date - timedelta(days=365 * trade_term)\n",
    "SPData=pd.DataFrame()\n",
    "\n",
    "# Fetch historical data from Yahoo Finance\n",
    "company = yf.Ticker(ticker_symbols)\n",
    "historical_data = company.history(period=\"max\")\n",
    "\n",
    "# Filter data for the specified date range (5 years from the end of September)\n",
    "historical_data = historical_data[(historical_data.index >= start_date) & (historical_data.index <= end_date)]\n",
    "\n",
    "# Reset the index to make the date a column\n",
    "historical_data.reset_index(inplace=True)\n",
    "\n",
    "historical_data['Ticker'] = ticker_symbols\n",
    "\n",
    "# Create a new DataFrame by concatenating filtered data\n",
    "SPData = pd.concat([SPData, historical_data])\n",
    "\n",
    "# Drop columns from the new DataFrame\n",
    "SPData = SPData.drop(columns=Useless_Columns)\n",
    "\n",
    "# Add new columns\n",
    "SPData['Brand_Name'] = 'SP500'\n",
    "SPData['Industry_Tag'] = 'Market Reference'\n",
    "SPData['Country'] = 'Global'\n",
    "\n",
    "# Drop rows with missing values (if needed)\n",
    "SPData = SPData.dropna()\n",
    "\n",
    "# Sort the DataFrame\n",
    "SPData.sort_values(['Ticker', 'Date'], inplace=True)\n",
    "\n",
    "# Initialize an empty DataFrameand list to store Beta values\n",
    "beta_df = pd.DataFrame(columns=['Ticker', 'Beta'])\n",
    "beta_data=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c104b596-9eb0-4b4f-b991-a67fff41bab5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate daily returns using the Open and Close columns\n",
    "Calculations_df['Daily_Return'] = Calculations_df['Close'].pct_change() * 100\n",
    "SPData['SP500_Daily_Return'] = SPData['Close'].pct_change() * 100\n",
    "\n",
    "\n",
    "# Create a new DataFrame for Compared_Calcs with 'Daily_Return' values\n",
    "Compared_Calcs = Calculations_df[['Ticker', 'Daily_Return', 'Date']].copy()\n",
    "\n",
    "# Check for missing values in 'Daily_Return' column of Compared_Calcs\n",
    "missing_values = Compared_Calcs['Daily_Return'].isna().sum()\n",
    "\n",
    "# Handle missing values (e.g., fill or drop them)\n",
    "if missing_values > 0:\n",
    "    Compared_Calcs['Daily_Return'].fillna(0, inplace=True)\n",
    "\n",
    "#Calculate cumulative daily returns for each Ticker\n",
    "Compared_Calcs['Cumulative_Return'] = (1 + Compared_Calcs['Daily_Return']).groupby(Compared_Calcs['Ticker']).cumprod()\n",
    "\n",
    "#Calculate the average annualized yield\n",
    "days_per_year = 252*trade_term  \n",
    "Compared_Calcs['Yield'] = (Compared_Calcs['Cumulative_Return'] ** (1 / days_per_year) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8fc6342-0013-449e-8de2-4f85c3541ab1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oluwa\\AppData\\Local\\Temp\\ipykernel_23316\\2289233961.py:24: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  covariance = np.cov(stock_data['Daily_Return'], stock_data['SP500_Daily_Return'])[0, 1]\n",
      "F:\\Hacks\\anaconda3\\envs\\DemiDev\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "F:\\Hacks\\anaconda3\\envs\\DemiDev\\Lib\\site-packages\\numpy\\lib\\function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "F:\\Hacks\\anaconda3\\envs\\DemiDev\\Lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "F:\\Hacks\\anaconda3\\envs\\DemiDev\\Lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "# Calculate Volatility\n",
    "stock_vol = Calculations_df.groupby('Ticker')['Daily_Return'].std()\n",
    "\n",
    "# Calculate Value at Risk on each section grouped by Ticker/ Date\n",
    "def calculate_var(group):\n",
    "    return group['Daily_Return'].quantile(1 - .95)\n",
    "\n",
    "# Apply the function to each group\n",
    "var_df = Compared_Calcs.groupby('Ticker').apply(calculate_var).reset_index()\n",
    "\n",
    "# Create a new dataframe with this info\n",
    "var_df.columns = ['Ticker', 'VaR']\n",
    "\n",
    "# Merge the stock data and S&P 500 data based on the index\n",
    "merged_data = Compared_Calcs.merge(SPData[['SP500_Daily_Return']], left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Calculate Beta for each Ticker\n",
    "for ticker in Compared_Calcs['Ticker'].unique():\n",
    "    if ticker != '^GSPC':\n",
    "        # Filter data for the current stock and ^GSPC\n",
    "        stock_data = merged_data[merged_data['Ticker'] == ticker]\n",
    "        \n",
    "        # Calculate the covariance between stock returns and ^GSPC returns\n",
    "        covariance = np.cov(stock_data['Daily_Return'], stock_data['SP500_Daily_Return'])[0, 1]\n",
    "        \n",
    "        # Calculate the variance of ^GSPC returns\n",
    "        variance_SP500 = np.var(stock_data['SP500_Daily_Return'])\n",
    "        \n",
    "        # Calculate Beta\n",
    "        beta = covariance / variance_SP500\n",
    "\n",
    "        # Append the data as a tuple to the list\n",
    "        beta_data.append((ticker, beta))\n",
    "        \n",
    "\n",
    "# Convert the list of tuples into a DataFrame\n",
    "beta_df = pd.DataFrame(beta_data, columns=['Ticker', 'Beta'])\n",
    "\n",
    "#Create a variable for the average bond yield ion a given period\n",
    "Avg_5Yr_Bond_Yield = Bond_yields_filtered['CDN.AVG.3YTO5Y.AVG'].mean()\n",
    "\n",
    "#Calculate the difference between the average bond yield and each stock's yield:\n",
    "Compared_Calcs['Bond Safety Ratio'] = abs(Compared_Calcs['Yield'] - Avg_5Yr_Bond_Yield)\n",
    "\n",
    "#Reorganize Compared Calcs by Ticker\n",
    "regrouped_compared_calcs = Compared_Calcs.groupby(['Ticker', 'Date']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c53d72f-f812-4c19-b01c-6279bed22d24",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Check for correlations\n",
    "correlation_matrix1 = regrouped_compared_calcs[['Bond Safety Ratio', 'Daily_Return']].corr()\n",
    "correlation_matrix2 = merged_data[['SP500_Daily_Return', 'Daily_Return']].corr()\n",
    "#Both have weak correlations | Abandoning correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c727c4e5-58fa-4173-aa21-caaf456c53ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop Null Values\n",
    "regrouped_compared_calcs.dropna()\n",
    "beta_df.dropna()\n",
    "var_df.dropna()\n",
    "stock_vol.dropna()\n",
    "SPData.dropna()\n",
    "\n",
    "# Find the top 50 highest cumulative returns while excluding 'inf' values\n",
    "top_cumulative_returns = regrouped_compared_calcs[regrouped_compared_calcs['Cumulative_Return'] != float('inf')]['Cumulative_Return'].nlargest(50).dropna()\n",
    "# Count occurrences of each 'Ticker'\n",
    "cumulative_ticker_count = top_cumulative_returns.groupby(level=0).size()\n",
    "cumulative_ticker_count = cumulative_ticker_count.sort_values(ascending=False)\n",
    "cumulative_ticker_count_list = cumulative_ticker_count.index.tolist()\n",
    "# Find the fifteen most frequent 'Ticker' values\n",
    "most_frequent_tickers_list = cumulative_ticker_count.nlargest(15).index.tolist()\n",
    "\n",
    "\n",
    "# Find the best stocks based on Beta\n",
    "lowest_risk_stocks = beta_df.sort_values(by='Beta').head(15).dropna()\n",
    "lowest_risk_stocks_list = lowest_risk_stocks['Ticker'].tolist()\n",
    "\n",
    "# Find the top 15 stocks with the lowest VaR\n",
    "lowest_var_stock = var_df.nsmallest(15, 'VaR').dropna()\n",
    "lowest_var_stock_list = lowest_var_stock['Ticker'].tolist()\n",
    "\n",
    "# Get the 15 cells with the lowest values\n",
    "lowest_volatility = stock_vol.nsmallest(15).dropna()\n",
    "lowest_volatility_list = lowest_volatility.index.tolist()\n",
    "\n",
    "# Combine all the lists into one\n",
    "low_risk_analysis_list = (\n",
    "    lowest_volatility_list +\n",
    "    lowest_var_stock_list +\n",
    "    lowest_risk_stocks_list +\n",
    "    most_frequent_tickers_list\n",
    ")\n",
    "\n",
    "# Create a dictionary to count the frequency of each unique value\n",
    "lr_stock_count = {}\n",
    "for stock in low_risk_analysis_list:\n",
    "    if stock in lr_stock_count:\n",
    "        lr_stock_count[stock] += 1\n",
    "    else:\n",
    "        lr_stock_count[stock] = 1\n",
    "\n",
    "# Sort the stocks by frequency (most frequent first)\n",
    "low_risk_stocks_master_list = sorted(lr_stock_count.keys(), key=lambda x: lr_stock_count[x], reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ecda3c-d3b9-43a7-aad7-a3c0be5a5459",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Find the 50 lowest cumulative returns while excluding 'inf' values\n",
    "worst_cumulative_returns = regrouped_compared_calcs[regrouped_compared_calcs['Cumulative_Return'] != float('inf')]['Cumulative_Return'].nsmallest(50).dropna()\n",
    "# Count occurrences of each 'Ticker'\n",
    "cumulative_ticker_count2 = worst_cumulative_returns.groupby(level=0).size()\n",
    "cumulative_ticker_count2 = cumulative_ticker_count2.sort_values(ascending=False)\n",
    "cumulative_ticker_count_list2 = cumulative_ticker_count2.index.tolist()\n",
    "# Find the fifteen most frequent 'Ticker' values\n",
    "most_frequent_tickers_list2 = cumulative_ticker_count2.nlargest(15).index.tolist()\n",
    "\n",
    "\n",
    "# Find the worst stocks based on Beta\n",
    "highest_risk_stocks = beta_df.sort_values(by='Beta').tail(15).dropna()\n",
    "highest_risk_stocks_list = highest_risk_stocks['Ticker'].tolist()\n",
    "\n",
    "# Find the 15 stocks with the lowest VaR\n",
    "highest_var_stock = var_df.nlargest(15, 'VaR').dropna()\n",
    "highest_var_stock_list = highest_var_stock['Ticker'].tolist()\n",
    "\n",
    "# Get the 15 cells with the lowest volatility values\n",
    "highest_volatility = stock_vol.nlargest(15).dropna()\n",
    "highest_volatility_list = highest_volatility.index.tolist()\n",
    "\n",
    "# Combine all the lists into one\n",
    "high_risk_analysis_list = (\n",
    "    highest_volatility_list +\n",
    "    highest_var_stock_list +\n",
    "    highest_risk_stocks_list +\n",
    "    most_frequent_tickers_list2 \n",
    ")\n",
    "\n",
    "# Create a dictionary to count the frequency of each unique value\n",
    "hr_stock_count = {}\n",
    "for stock in high_risk_analysis_list:\n",
    "    if stock in hr_stock_count:\n",
    "        hr_stock_count[stock] += 1\n",
    "    else:\n",
    "        hr_stock_count[stock] = 1\n",
    "\n",
    "# Sort the stocks by frequency (most frequent first)\n",
    "high_risk_stocks_master_list = sorted(hr_stock_count.keys(), key=lambda x: hr_stock_count[x], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb9c885e-b29b-4e49-ae58-252c2c0b7773",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Set a variable for the average risk by beta\n",
    "rsk_avg = beta_df['Beta'].mean()\n",
    "\n",
    "# Get the rows that are within an acceptable range of the average beta\n",
    "average_risk_stocks = beta_df[(beta_df['Beta'] >= rsk_avg - .1) & (beta_df['Beta'] <= rsk_avg + .1)].dropna()\n",
    "\n",
    "# Get the list of tickers for the stocks with average risk\n",
    "average_risk_stocks_list = average_risk_stocks['Ticker'].tolist()\n",
    "\n",
    "# Sort the stocks in average_risk_stocks_list by proximity to the average\n",
    "average_risk_analysis_list = sorted(average_risk_stocks_list, key=lambda x: abs(beta_df.loc[beta_df['Ticker'] == x, 'Beta'].values[0] - rsk_avg))\n",
    "\n",
    "\n",
    "  \n",
    "# Set a variable for average cumulative return\n",
    "cum_avg_ret=regrouped_compared_calcs['Cumulative_Return'].groupby('Ticker').mean().dropna()\n",
    "\n",
    "# Calculate the average return\n",
    "avg_return = cum_avg_ret.mean()  \n",
    "\n",
    "# Filter the series by proximity to the average. Find the values that are within 1.0 of the average\n",
    "average_risk_returns_list1 = cum_avg_ret[(cum_avg_ret >= avg_return - 1)].index.tolist()\n",
    "average_risk_returns_list2 = cum_avg_ret[(cum_avg_ret <= avg_return + 1)].index.tolist()\n",
    "\n",
    "# Sort both lists by proximity to avg_return\n",
    "sorted_list1 = sorted(average_risk_returns_list1, key=lambda x: abs(cum_avg_ret[x] - avg_return))\n",
    "sorted_list2 = sorted(average_risk_returns_list2, key=lambda x: abs(cum_avg_ret[x] - avg_return))\n",
    "\n",
    "average_risk_returns_list = (sorted_list1 + sorted_list2)\n",
    "\n",
    "# Sort the stocks in average_risk_returns_list by proximity to the average risk based on cumulative returns\n",
    "average_risk_returns_master_list = sorted(average_risk_returns_list, key=lambda x: abs(cum_avg_ret[x] - avg_return))\n",
    "\n",
    "\n",
    "\n",
    "# Creat the average Value At Risk Variable\n",
    "var_df['VaR'] = var_df['VaR'].astype(float)\n",
    "avg_var = var_df['VaR'].mean()\n",
    "\n",
    "# Calculate the absolute difference between each VaR value and the average VaR\n",
    "var_difference = var_df['VaR'].sub(avg_var).abs()\n",
    "\n",
    "# Sort the VaR values by proximity to the average VaR\n",
    "sorted_var_list = var_df['Ticker'].tolist()\n",
    "sorted_var_list.sort(key=lambda x: var_difference[var_df.loc[var_df['Ticker'] == x, 'VaR'].index[0]])\n",
    "\n",
    "# Get the top 15 values closest to the average VaR\n",
    "top_15_closest_to_avg_var = sorted_var_list[:15]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the average volatility\n",
    "avg_volatility = stock_vol.mean()\n",
    "\n",
    "# Calculate the absolute difference between each stock's volatility and the average volatility\n",
    "volatility_difference = stock_vol.sub(avg_volatility).abs()\n",
    "\n",
    "# Sort the list of stocks by proximity to the average volatility\n",
    "sorted_volatility_list = stock_vol.index.tolist()\n",
    "sorted_volatility_list.sort(key=lambda x: volatility_difference[x])\n",
    "\n",
    "# Get the top 15 stocks closest to the average volatility\n",
    "top_15_closest_to_avg_volatility = sorted_volatility_list[:15]\n",
    "\n",
    "\n",
    "\n",
    "#Combine Lists\n",
    "mid_combined_list= (top_15_closest_to_avg_var + top_15_closest_to_avg_volatility + average_risk_returns_master_list + average_risk_analysis_list)\n",
    "mid_count= Counter(mid_combined_list)\n",
    "mid_risk_stocks_master_list = [item[0] for item in sorted(mid_count.items(), key=lambda x: x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03cef68f-f5ce-4fe5-9c96-d77d925431e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Define the function to show a recommendaiton of 10 stocks\n",
    "def print_first_10_strings(input_list):\n",
    "    return input_list[:10]\n",
    "    \n",
    "        \n",
    "#Define Final Recommendation\n",
    "if user_risk == 'high':\n",
    "    risk_tickers = print_first_10_strings(high_risk_stocks_master_list)\n",
    "elif user_risk == 'low':\n",
    "    risk_tickers = print_first_10_strings(low_risk_stocks_master_list)\n",
    "elif user_risk == 'mid':\n",
    "    risk_tickers = print_first_10_strings(mid_risk_stocks_master_list)\n",
    "else:\n",
    "    print(\"Invalid user_risk value\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9476e834-9cc9-4ca9-903e-eedc40f57153",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Display Final Recommendations With All Data\n",
    "\n",
    "# Filter DataFrames by matching tickers\n",
    "var_df_filtered = var_df[var_df['Ticker'].isin(risk_tickers)]\n",
    "beta_df_filtered = beta_df[beta_df['Ticker'].isin(risk_tickers)]\n",
    "stock_vol_filtered = stock_vol[stock_vol.index.isin(risk_tickers)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb16cab-e216-48d9-8cc1-f62b7f642593",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Make the volatility data a dataframe\n",
    "stock_vol_filtered = stock_vol_filtered.to_frame()\n",
    "\n",
    "# Rename the Volatility Column\n",
    "stock_vol_filtered.columns = ['Volatility']\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = var_df_filtered.merge(beta_df_filtered, on='Ticker', how='left')\n",
    "\n",
    "# Now, 'merged_df' contains 'Value At Risk', 'Beta', and 'Volatility' columns with 'Ticker' as the index\n",
    "merged_df = merged_df.set_index('Ticker')\n",
    "\n",
    "# Combine 'merged_df' with 'stock_vol_filtered' by the common index 'Ticker'\n",
    "risk_analyzer = merged_df.join(stock_vol_filtered)\n",
    "\n",
    "# Rename the columns to match your desired column names\n",
    "risk_analyzer.rename(columns={'VaR': 'Value At Risk'}, inplace=True)\n",
    "\n",
    "# Create a custom sorting order based on 'risk_tickers'\n",
    "custom_order = {ticker: order for order, ticker in enumerate(risk_tickers)}\n",
    "\n",
    "\n",
    "# Use the custom order to sort the DataFrame\n",
    "risk_analyzer['sorting_order'] = risk_analyzer.index.map(custom_order)\n",
    "risk_analyzer.sort_values(by='sorting_order', inplace=True)\n",
    "risk_analyzer.drop('sorting_order', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bee798a4-fab8-42c3-b9f2-9ad8d559b874",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Organize the original World_Data dataset by the final recommended list\n",
    "\n",
    "#Remove useless columns\n",
    "Useless_Columns2=['Dividends', 'Stock Splits', 'Industry_Tag', 'Country']\n",
    "Final_Stock_Display= World_Stocks.drop(columns=Useless_Columns2)\n",
    "\n",
    "#Cut the Date data down to only the daily\n",
    "Final_Stock_Display['Date'] = Final_Stock_Display['Date'].dt.date\n",
    "\n",
    "#Cut the Data down to only tickers that match the final recommended list\n",
    "Final_Stock_Display=Final_Stock_Display[Final_Stock_Display['Ticker'].isin(risk_tickers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3940267e-6aa5-48a8-87e3-92b33b8b8e04",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TSLA', 'ZI', 'DIS', 'NVDA', 'ADBE', 'TGT', 'DAL', 'AAPL', 'RBLX', 'ABNB']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print Final Recommendation\n",
    "risk_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0802ebc-168a-41cc-aada-80c218cfe808",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value At Risk</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Volatility</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>-3.247757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.786726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZI</th>\n",
       "      <td>-3.217752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.804434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-3.089506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.626620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>-3.004797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.085868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADBE</th>\n",
       "      <td>-2.766546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.997285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGT</th>\n",
       "      <td>-2.580326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.690355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAL</th>\n",
       "      <td>-2.968333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.914604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-2.900809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.550962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBLX</th>\n",
       "      <td>-2.745507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.455562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABNB</th>\n",
       "      <td>-2.686514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.836571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Value At Risk  Beta  Volatility\n",
       "Ticker                                 \n",
       "TSLA        -3.247757   NaN   18.786726\n",
       "ZI          -3.217752   NaN   16.804434\n",
       "DIS         -3.089506   NaN   23.626620\n",
       "NVDA        -3.004797   NaN   61.085868\n",
       "ADBE        -2.766546   NaN   48.997285\n",
       "TGT         -2.580326   NaN   31.690355\n",
       "DAL         -2.968333   NaN    3.914604\n",
       "AAPL        -2.900809   NaN    1.550962\n",
       "RBLX        -2.745507   NaN   98.455562\n",
       "ABNB        -2.686514   NaN    4.836571"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show Final Dataset\n",
    "risk_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef3cf3aa-921a-4798-b642-ff7de16d154a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>179.259995</td>\n",
       "      <td>179.699997</td>\n",
       "      <td>175.399994</td>\n",
       "      <td>175.490005</td>\n",
       "      <td>58436200.0</td>\n",
       "      <td>apple</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>120.580002</td>\n",
       "      <td>121.540001</td>\n",
       "      <td>120.070000</td>\n",
       "      <td>120.410004</td>\n",
       "      <td>3263500.0</td>\n",
       "      <td>target</td>\n",
       "      <td>TGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>82.029999</td>\n",
       "      <td>83.199997</td>\n",
       "      <td>81.639999</td>\n",
       "      <td>82.559998</td>\n",
       "      <td>12715200.0</td>\n",
       "      <td>the walt disney company</td>\n",
       "      <td>DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>27.219999</td>\n",
       "      <td>27.290001</td>\n",
       "      <td>26.200001</td>\n",
       "      <td>26.250000</td>\n",
       "      <td>7819500.0</td>\n",
       "      <td>roblox</td>\n",
       "      <td>RBLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-09-20</td>\n",
       "      <td>39.770000</td>\n",
       "      <td>39.869999</td>\n",
       "      <td>38.770000</td>\n",
       "      <td>38.880001</td>\n",
       "      <td>7000200.0</td>\n",
       "      <td>delta air lines</td>\n",
       "      <td>DAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211700</th>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>17.860001</td>\n",
       "      <td>17.985001</td>\n",
       "      <td>17.730000</td>\n",
       "      <td>17.840000</td>\n",
       "      <td>5188700.0</td>\n",
       "      <td>zoominfo</td>\n",
       "      <td>ZI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211701</th>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>17.830000</td>\n",
       "      <td>18.040001</td>\n",
       "      <td>17.709999</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>6049300.0</td>\n",
       "      <td>zoominfo</td>\n",
       "      <td>ZI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211702</th>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>17.920000</td>\n",
       "      <td>18.330000</td>\n",
       "      <td>17.870001</td>\n",
       "      <td>18.020000</td>\n",
       "      <td>8268200.0</td>\n",
       "      <td>zoominfo</td>\n",
       "      <td>ZI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211703</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>18.629999</td>\n",
       "      <td>18.150000</td>\n",
       "      <td>18.580000</td>\n",
       "      <td>6501900.0</td>\n",
       "      <td>zoominfo</td>\n",
       "      <td>ZI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211704</th>\n",
       "      <td>2023-09-05</td>\n",
       "      <td>18.080000</td>\n",
       "      <td>18.299999</td>\n",
       "      <td>17.910000</td>\n",
       "      <td>18.110001</td>\n",
       "      <td>4596900.0</td>\n",
       "      <td>zoominfo</td>\n",
       "      <td>ZI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39476 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date        Open        High         Low       Close  \\\n",
       "4       2023-09-20  179.259995  179.699997  175.399994  175.490005   \n",
       "6       2023-09-20  120.580002  121.540001  120.070000  120.410004   \n",
       "10      2023-09-20   82.029999   83.199997   81.639999   82.559998   \n",
       "11      2023-09-20   27.219999   27.290001   26.200001   26.250000   \n",
       "13      2023-09-20   39.770000   39.869999   38.770000   38.880001   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "211700  2023-08-29   17.860001   17.985001   17.730000   17.840000   \n",
       "211701  2023-08-30   17.830000   18.040001   17.709999   17.790001   \n",
       "211702  2023-08-31   17.920000   18.330000   17.870001   18.020000   \n",
       "211703  2023-09-01   18.180000   18.629999   18.150000   18.580000   \n",
       "211704  2023-09-05   18.080000   18.299999   17.910000   18.110001   \n",
       "\n",
       "            Volume               Brand_Name Ticker  \n",
       "4       58436200.0                    apple   AAPL  \n",
       "6        3263500.0                   target    TGT  \n",
       "10      12715200.0  the walt disney company    DIS  \n",
       "11       7819500.0                   roblox   RBLX  \n",
       "13       7000200.0          delta air lines    DAL  \n",
       "...            ...                      ...    ...  \n",
       "211700   5188700.0                 zoominfo     ZI  \n",
       "211701   6049300.0                 zoominfo     ZI  \n",
       "211702   8268200.0                 zoominfo     ZI  \n",
       "211703   6501900.0                 zoominfo     ZI  \n",
       "211704   4596900.0                 zoominfo     ZI  \n",
       "\n",
       "[39476 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display World Data for Final Recommendations\n",
    "Final_Stock_Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc902ad-6583-439e-a893-bca769d0365d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
